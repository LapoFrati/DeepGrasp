{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 0\n"
     ]
    }
   ],
   "source": [
    "import setGPU\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import pandas\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from functools import total_ordering\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from JupyterLoader import NotebookFinder\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /home/frati/new_Grasping/code/dataloaders/synth_Berlino_dataloader.ipynb\n"
     ]
    }
   ],
   "source": [
    "#from dataloaders.unified_Berlino_dataloader import get_loaders\n",
    "from dataloaders.synth_Berlino_dataloader import get_loaders\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "dataloaders, display, vocab = get_loaders(folder='/home/frati/',\n",
    "                               split = (0.3,0.5), \n",
    "                               dataset='full',\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=True,\n",
    "                               num_workers=num_workers,\n",
    "                               seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(phase):\n",
    "    return next(iter(dataloaders[phase]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models.colorNet import ColorNet\n",
    "#from models.viewPooler import ViewPooler\n",
    "#from models.partialVGG import get_partialVGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utilities.ipynb\n"
     ]
    }
   ],
   "source": [
    "from utilities import AverageMeter, accuracy, get_trainable_parameters, varify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "args = {'model_path':'./models/',\n",
    " 'crop_size': 224,\n",
    " 'vocab_path':'./data/vocab.pkl',\n",
    " 'image_dir':'./data/resized2014',\n",
    " 'caption_path':'./data/annotations/captions_train2014.json',\n",
    " 'log_step':10,\n",
    " 'save_step':1000,\n",
    " 'embed_size':256,\n",
    " 'hidden_size':512,\n",
    " 'num_layers':1,\n",
    " 'num_epochs':5,\n",
    " 'batch_size':128,\n",
    " 'num_workers':2,\n",
    " 'learning_rate':0.001}\n",
    "args = SimpleNamespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViewPooler(nn.Module):\n",
    "    def __init__(self, embed_size, views):\n",
    "        super(ViewPooler, self).__init__()\n",
    "        self.features_extractor = models.vgg16_bn(pretrained=True).features\n",
    "        for param in self.features_extractor.parameters(): # freeze VGG\n",
    "            param.requires_grad = False\n",
    "        self.view_pooling = nn.MaxPool2d(kernel_size=(views,1))\n",
    "        in_features = 512*7*7\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_1 = nn.Linear(in_features, embed_size)\n",
    "        #self.fc_2 = nn.Linear(4096,embed_size)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.bn = nn.BatchNorm1d(in_features, momentum=0.01)\n",
    "\n",
    "    def forward(self, views):\n",
    "        views_features = [self.features_extractor(view) for view in views]\n",
    "        \n",
    "        ims,filters,h,w = views_features[0].shape\n",
    "        \n",
    "        flat_views = [view.view(ims,-1) for view in views_features]\n",
    "        stacked_views = torch.stack(flat_views,dim=1)\n",
    "        pooled_views = self.view_pooling(stacked_views).squeeze()\n",
    "        \n",
    "        features = Variable(pooled_views.data) # can set volatile to input images to avoid wasted gradients\n",
    "        features = self.bn(features)\n",
    "        features = self.fc_1(features)\n",
    "        \n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorNet(nn.Module):\n",
    "    def __init__(self, pretrained = None):\n",
    "        super(ColorNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 1)\n",
    "        self.conv2 = nn.Conv2d(10, 3, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(3,affine=True)\n",
    "        if pretrained is None:\n",
    "            self.init_weights()\n",
    "        else:\n",
    "            state = torch.load(pretrained, map_location=lambda storage, loc: storage)\n",
    "            self.load_state_dict(state['state_dict'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "    \n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize the weights.\"\"\"\n",
    "        self.conv1.weight.data.normal_(1/3, 0.01)\n",
    "        self.conv1.bias.data.fill_(0)\n",
    "        self.conv2.weight.data.normal_(1/3, 0.01)\n",
    "        self.conv2.bias.data.fill_(0)\n",
    "        \n",
    "class colorPooler(nn.Module):\n",
    "    def __init__(self, embed_size, views):\n",
    "        super(colorPooler, self).__init__()\n",
    "        self.features_extractor = nn.Sequential(ColorNet(pretrained='/home/frati/new_Grasping/code/models/pseudo_colorer.pth.tar'), models.vgg16_bn(pretrained=True).features)\n",
    "        for param in self.features_extractor[1].parameters(): # freeze VGG\n",
    "            param.requires_grad = False\n",
    "        self.view_pooling = nn.MaxPool2d(kernel_size=(views,1))\n",
    "        in_features = 512*7*7\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_1 = nn.Linear(in_features, embed_size)\n",
    "        #self.fc_2 = nn.Linear(4096,embed_size)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.bn = nn.BatchNorm1d(in_features, momentum=0.01)\n",
    "\n",
    "    def forward(self, views):\n",
    "        views_features = [self.features_extractor(view) for view in views]\n",
    "        \n",
    "        ims,filters,h,w = views_features[0].shape\n",
    "        \n",
    "        flat_views = [view.view(ims,-1) for view in views_features]\n",
    "        stacked_views = torch.stack(flat_views,dim=1)\n",
    "        pooled_views = self.view_pooling(stacked_views).squeeze()\n",
    "        \n",
    "        features = Variable(pooled_views.data) # can set volatile to input images to avoid wasted gradients\n",
    "        features = self.bn(features)\n",
    "        features = self.fc_1(features)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = colorPooler(embed_size = args.embed_size, views=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n",
    "        \"\"\"Set the hyper-parameters and build the layers.\"\"\"\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize weights.\"\"\"\n",
    "        self.embed.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.linear.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.linear.bias.data.fill_(0)\n",
    "        \n",
    "    def forward(self, features, tags, lengths):\n",
    "        \"\"\"Decode image feature vectors and generates captions.\"\"\"\n",
    "        embeddings = self.embed(tags)\n",
    "        embeddings = torch.cat((features.unsqueeze(1), embeddings), 1)\n",
    "        packed = pack_padded_sequence(embeddings, lengths, batch_first=True) \n",
    "        hiddens, _ = self.lstm(packed)\n",
    "        outputs = self.linear(hiddens[0])\n",
    "        return outputs\n",
    "    \n",
    "    def sample(self, features, states=None):\n",
    "        \"\"\"Samples captions for given image features (Greedy search).\"\"\"\n",
    "        sampled_ids = []\n",
    "        inputs = features.unsqueeze(1)\n",
    "        for i in range(20):                                      # maximum sampling length\n",
    "            hiddens, states = self.lstm(inputs, states)          # (batch_size, 1, hidden_size), \n",
    "            outputs = self.linear(hiddens.squeeze(1))            # (batch_size, vocab_size)\n",
    "            predicted = outputs.max(1)[1]\n",
    "            sampled_ids.append(predicted)\n",
    "            inputs = self.embed(predicted)\n",
    "            inputs = inputs.unsqueeze(1)                         # (batch_size, 1, embed_size)\n",
    "        sampled_ids = torch.stack(sampled_ids, 1)                  # (batch_size, 20)\n",
    "        return sampled_ids.squeeze()\n",
    "    \n",
    "    def my_sample(self, features, states=None):\n",
    "        \"\"\"Samples captions for given image features (Greedy search).\"\"\"\n",
    "        sampled_ids = []\n",
    "        inputs = features.unsqueeze(1)\n",
    "        stop = False\n",
    "        while not stop:                                      # maximum sampling length\n",
    "            hiddens, states = self.lstm(inputs, states)          # (batch_size, 1, hidden_size), \n",
    "            outputs = self.linear(hiddens.squeeze(1))            # (batch_size, vocab_size)\n",
    "            predicted = outputs.max(1)[1]\n",
    "            sampled_ids.append(predicted)\n",
    "            stop = vocab.is_stop(predicted.cpu().data.numpy())\n",
    "            inputs = self.embed(predicted)\n",
    "            inputs = inputs.unsqueeze(1)                         # (batch_size, 1, embed_size)\n",
    "        sampled_ids = torch.stack(sampled_ids, 1)                  # (batch_size, 20)\n",
    "        return sampled_ids.squeeze()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = DecoderRNN(args.embed_size, args.hidden_size, len(vocab), args.num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters:\t     6473019\n",
      "Frozen parameters:\t    14723136\n"
     ]
    }
   ],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "params = list(decoder.parameters()) + get_trainable_parameters(encoder)\n",
    "optimizer = torch.optim.Adam(params, lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/5], Step [0/377], Loss: 8.2953, Perplexity: 4005.1631\n",
      "Epoch [0/5], Step [10/377], Loss: 5.8576, Perplexity: 349.8797\n",
      "Epoch [0/5], Step [20/377], Loss: 3.5936, Perplexity: 36.3643\n",
      "Epoch [0/5], Step [30/377], Loss: 3.4270, Perplexity: 30.7829\n",
      "Epoch [0/5], Step [40/377], Loss: 3.0013, Perplexity: 20.1125\n",
      "Epoch [0/5], Step [50/377], Loss: 3.4989, Perplexity: 33.0779\n",
      "Epoch [0/5], Step [60/377], Loss: 2.7248, Perplexity: 15.2532\n",
      "Epoch [0/5], Step [70/377], Loss: 2.9636, Perplexity: 19.3676\n",
      "Epoch [0/5], Step [80/377], Loss: 2.1235, Perplexity: 8.3602\n",
      "Epoch [0/5], Step [90/377], Loss: 2.1456, Perplexity: 8.5469\n",
      "Epoch [0/5], Step [100/377], Loss: 2.5355, Perplexity: 12.6222\n",
      "Epoch [0/5], Step [110/377], Loss: 2.7783, Perplexity: 16.0911\n",
      "Epoch [0/5], Step [120/377], Loss: 2.2242, Perplexity: 9.2464\n",
      "Epoch [0/5], Step [130/377], Loss: 2.3269, Perplexity: 10.2457\n",
      "Epoch [0/5], Step [140/377], Loss: 2.2843, Perplexity: 9.8187\n",
      "Epoch [0/5], Step [150/377], Loss: 1.8547, Perplexity: 6.3896\n",
      "Epoch [0/5], Step [160/377], Loss: 2.5186, Perplexity: 12.4109\n",
      "Epoch [0/5], Step [170/377], Loss: 2.3350, Perplexity: 10.3293\n",
      "Epoch [0/5], Step [180/377], Loss: 1.5991, Perplexity: 4.9485\n",
      "Epoch [0/5], Step [190/377], Loss: 1.6127, Perplexity: 5.0165\n",
      "Epoch [0/5], Step [200/377], Loss: 2.1770, Perplexity: 8.8198\n",
      "Epoch [0/5], Step [210/377], Loss: 1.7508, Perplexity: 5.7594\n",
      "Epoch [0/5], Step [220/377], Loss: 2.0573, Perplexity: 7.8249\n",
      "Epoch [0/5], Step [230/377], Loss: 1.6215, Perplexity: 5.0609\n",
      "Epoch [0/5], Step [240/377], Loss: 2.0264, Perplexity: 7.5864\n",
      "Epoch [0/5], Step [250/377], Loss: 1.7722, Perplexity: 5.8836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Process Process-4:\n",
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7f8596747710>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 333, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 319, in _shutdown_workers\n",
      "    self.data_queue.get()\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/frati/miniconda3/envs/pytorch3.1/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 137042) exited unexpectedly with exit code 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# init descriptors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_rnn_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_input_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36minit_rnn_descriptor\u001b[0;34m(fn, handle)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     )\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, hidden_size, num_layers, dropout_desc, input_mode, bidirectional, mode, datatype)\u001b[0m\n\u001b[1;32m    260\u001b[0m             if version() >= 7000 and int(cuda[0]) >= 9 and (\n\u001b[0;32m--> 261\u001b[0;31m                     torch.cuda.get_device_capability(torch.cuda.current_device())[0] >= 7):\n\u001b[0m\u001b[1;32m    262\u001b[0m                 \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnnSetRNNMatrixMathType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCUDNN_DEFAULT_MATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDeviceCapability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-05e4e90b7d23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-3cf9ca1c36c2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, tags, lengths)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mhiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         )\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# init descriptors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_rnn_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_input_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_descs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptor_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3.1/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 137042) exited unexpectedly with exit code 1."
     ]
    }
   ],
   "source": [
    "data_loader = dataloaders['train']\n",
    "\n",
    "total_step = len(data_loader)\n",
    "best_valid = 0\n",
    "best_enc = encoder.state_dict()\n",
    "best_dec = decoder.state_dict()\n",
    "\n",
    "for epoch in range(args.num_epochs):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    for i, (images, captions, lengths, objs) in enumerate(dataloaders['train']):\n",
    "\n",
    "        # Set mini-batch dataset\n",
    "        images = varify(images, volatile=True)\n",
    "        ###\n",
    "        images = [view[:,1,...].unsqueeze(1) for view in images]\n",
    "        ###\n",
    "        captions = varify(captions)\n",
    "        targets = pack_padded_sequence(captions, lengths, batch_first=True)[0]\n",
    "\n",
    "        # Forward, Backward and Optimize\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions, lengths)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print log info\n",
    "        if i % args.log_step == 0:\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f'\n",
    "                  %(epoch, args.num_epochs, i, total_step, \n",
    "                    loss.data[0], np.exp(loss.data[0])))\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    correct = 0\n",
    "    num_tags = 0\n",
    "    for i, (images, captions, lengths, objs) in enumerate(dataloaders['valid']):\n",
    "        # Set mini-batch dataset\n",
    "        images = varify(images, volatile=True)\n",
    "        ###\n",
    "        images = [view[:,1,...].unsqueeze(1) for view in images]\n",
    "        ###\n",
    "        captions = varify(captions,volatile=True)\n",
    "        targets = pack_padded_sequence(captions, lengths, batch_first=True)[0]\n",
    "\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions, lengths)\n",
    "        loss = criterion(outputs, targets)\n",
    "        _,preds = torch.max(outputs,1)\n",
    "        correct += int(torch.sum(preds == targets))\n",
    "        num_tags += float(sum(lengths))\n",
    "        \n",
    "    valid_acc = correct/num_tags\n",
    "    if valid_acc > best_valid:\n",
    "        best_valid = valid_acc\n",
    "        best_enc = encoder.state_dict()\n",
    "        best_dec = decoder.state_dict()\n",
    "    print('Validation Accuracy {:.3f}'.format(valid_acc))\n",
    "print(\"Best validation acc: {:.2f}\".format(valid_acc))\n",
    "encoder.load_state_dict(best_enc)\n",
    "decoder.load_state_dict(best_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(encoder.state_dict(),\"my_encoder.pkl\")\n",
    "#torch.save(decoder.state_dict(),\"my_decoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Beam():\n",
    "    \n",
    "    def __init__(self, decoder, embed, translate, beam_size, vocabulary, penalty):\n",
    "        self.decoder = decoder\n",
    "        self.embed = embed\n",
    "        self.translate = translate\n",
    "        self.beam_size = beam_size\n",
    "        self.vocab = vocab\n",
    "        self.penalty = penalty\n",
    "        self.finished_beams = []\n",
    "        self.logsoftmax = torch.nn.LogSoftmax()\n",
    "        self.beam_started = False\n",
    "        self.states = None\n",
    "        \n",
    "    def start_beams(self,seed):\n",
    "        self.finished_beams = []\n",
    "        seed = seed.unsqueeze(0).unsqueeze(0) # beam deals with one view at a time\n",
    "        outputs, state = self.decoder(seed, None)\n",
    "        decoded = self.translate(outputs.squeeze(1))\n",
    "        probs, preds = self.logsoftmax(decoded).topk(self.beam_size) # populate beam with the first characters\n",
    "        self.beam = [Candidate(probs[0,i],[preds[0,i]],preds[0,i],state,self.penalty) for i in range((probs.shape)[1])]\n",
    "    \n",
    "    def sample_beams(self):\n",
    "        safety = True\n",
    "        safety_counter = 0\n",
    "        safety_limit = 100\n",
    "        while (len(self.finished_beams) < self.beam_size and safety):\n",
    "            candidates_prob = []\n",
    "            new_states = []\n",
    "            for candidate in self.beam:\n",
    "                pred, state = candidate\n",
    "                # embed\n",
    "                emb = self.embed(pred) # embedding is [100]\n",
    "                emb = emb.view(1,1,-1) # turn embedding into batch,seq,values : 1,1,100\n",
    "                # compute\n",
    "                new_output, new_state = self.decoder(emb,state)\n",
    "                new_states.append(new_state)\n",
    "                # decode\n",
    "                new_output.view(1,-1) # remove fake batch\n",
    "                new_decoded = self.translate(new_output).view(1,-1)\n",
    "                # score\n",
    "                word_probs = self.logsoftmax(new_decoded)\n",
    "\n",
    "                #word_probs += candidate.prob\n",
    "                normalized_probs = candidate.normalize_probs(word_probs)\n",
    "\n",
    "                candidates_prob.append(normalized_probs)\n",
    "\n",
    "            flat_candidates = torch.cat(candidates_prob).view(-1)\n",
    "            \n",
    "            top_scores, top_words = flat_candidates.topk(self.beam_size)\n",
    "            new_words = top_words % len(vocab)\n",
    "            beams_id = top_words.cpu().data.numpy() // len(vocab)\n",
    "            \n",
    "            expanded_beam = []\n",
    "\n",
    "            for beam_id, new_word, score in zip(beams_id, new_words, top_scores):\n",
    "                new_candidate = self.beam[beam_id].update(score, new_word, new_states[beam_id])\n",
    "                if vocab.is_stop(new_word.cpu().data.numpy()):\n",
    "                    self.finished_beams.append(new_candidate)\n",
    "                else:\n",
    "                    expanded_beam.append(new_candidate)    \n",
    "            \n",
    "            self.beam = expanded_beam\n",
    "            #print(\"Beam: \",len(self.beam))\n",
    "            #print(\"Finished: \",len(self.finished_beams))\n",
    "            safety_counter += 1\n",
    "            safety = safety_counter < safety_limit\n",
    "    \n",
    "    def get_best(self):\n",
    "        if(len(self.finished_beams) <= 0):\n",
    "            raise RuntimeError('Beams have not been expanded')\n",
    "            \n",
    "        self.finished_beams = sorted(self.finished_beams,reverse=True, key=lambda x: x.prob)\n",
    "        return (torch.stack(self.finished_beams[0].seq),self.finished_beams[0].prob)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter(self.beam)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return ''.join([ el.__str__() + \"\\n\" for el in self.finished_beams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Candidate():\n",
    "    def __init__(self, prob, sequence, last_word, state, penalty):\n",
    "        self.state = state\n",
    "        self.prob = float(prob)\n",
    "        self.last_word = last_word\n",
    "        self.seq = sequence\n",
    "        self.penalty = penalty\n",
    "    \n",
    "    def update(self, prob, new_word, state):\n",
    "        return Candidate(prob, self.seq + [new_word], new_word, state, self.penalty)\n",
    "        \n",
    "    def normalize_probs(self,new_probs):\n",
    "        return (new_probs + self.prob*(len(self.seq)**self.penalty)/((len(self.seq) + 1)**self.penalty))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter((self.last_word, self.state))\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Seq: {} Prob: {:.2f}\".format([int(el) for el in self.seq],self.prob)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beam = Beam(decoder.lstm, decoder.embed, decoder.linear, 5, vocab, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beam.start_beams(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for el in beam.beam:\n",
    "#    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beam.sample_beams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for el in beam.finished_beams:\n",
    "#    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "ix_to_obj = list(pandas.read_pickle('/home/frati/Grasping/Squared/index.pkl.compress', compression='gzip'))\n",
    "\n",
    "obj_to_ix = {}\n",
    "for idx, el in enumerate(ix_to_obj):\n",
    "    obj_to_ix[el] = idx\n",
    "\n",
    "flat_obj = ['key','button','cd','credit_card','game_card','comb']\n",
    "tall_obj = ['glasses','matchbox','chestnut','toy','salt_shaker','tape']\n",
    "big_obj = ['book','bowl','plate','coffee_mug']\n",
    "long_obj = ['cigarette','marker','screw_driver', 'shashlik']\n",
    "small_obj = [ 'french_chalk',  'match', 'rubber_band', 'screw', 'shell']\n",
    "\n",
    "all_objs = flat_obj+tall_obj+big_obj+long_obj+small_obj\n",
    "print(len(all_objs))\n",
    "\n",
    "obj_categories = {'flat' : flat_obj,\n",
    "                  'tall' : tall_obj,\n",
    "                  'big'  : big_obj,\n",
    "                  'long' : long_obj,\n",
    "                  'small': small_obj}\n",
    "\n",
    "obj_to_cat = {}\n",
    "for cat, objs in obj_categories.items():\n",
    "    for obj in objs:\n",
    "        obj_to_cat[obj] = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "views, tags, lengths, objs = next(iter(dataloaders['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 224, 224])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[view[:,1,...].unsqueeze(1) for view in views][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 224, 224])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plate\n",
      "plate\n",
      "key\n",
      "credit_card\n",
      "salt_shaker\n",
      "button\n",
      "matchbox\n",
      "salt_shaker\n"
     ]
    }
   ],
   "source": [
    "for el in objs:\n",
    "    print(ix_to_obj[el])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=224x224 at 0x7FF40190E780>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.plot_tensor(views[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_seqs(pred,targ):\n",
    "    disance = levenshtein(pred,targ)\n",
    "    return 1 - ((disance)/len(pred))\n",
    "\n",
    "def levenshtein(a,b):\n",
    "    \"Calculates the Levenshtein distance between a and b.\"\n",
    "    a = a.cpu().data.numpy()\n",
    "    b = b.cpu().numpy()\n",
    "    n, m = len(a), len(b)\n",
    "    if n > m:\n",
    "        # Make sure n <= m, to use O(min(n,m)) space\n",
    "        a,b = b,a\n",
    "        n,m = m,n\n",
    "        \n",
    "    current = range(n+1)\n",
    "    for i in range(1,m+1):\n",
    "        previous, current = current, [i]+[0]*n\n",
    "        for j in range(1,n+1):\n",
    "            add, delete = previous[j]+1, current[j-1]+1\n",
    "            change = previous[j-1]\n",
    "            if a[j-1] != b[i-1]:\n",
    "                change = change + 1\n",
    "            current[j] = min(add, delete, change)\n",
    "            \n",
    "    return current[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "metrics = {\"acc\":{}, \"greedy\":{}, \"beam\":{}}\n",
    "for key in metrics: \n",
    "    results = {}\n",
    "    for i in range(25):\n",
    "        results[i] =  []\n",
    "    metrics[key] = results\n",
    "    \n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "beam = Beam(decoder.lstm, decoder.embed, decoder.linear, 5, vocab, 0.7)\n",
    "for i, (images, captions, lengths, objs) in enumerate(dataloaders['test']):\n",
    "    # Set mini-batch dataset\n",
    "    images = varify(images, volatile=True)\n",
    "    ###\n",
    "    images = [view[:,1,...].unsqueeze(1) for view in images]\n",
    "    ###\n",
    "    features = encoder(images)\n",
    "    print(i)\n",
    "    \n",
    "    #batch\n",
    "    for i in range(features.shape[0]):\n",
    "        target = captions[i]\n",
    "        tot = lengths[i]\n",
    "        \n",
    "        sample_id = decoder.sample(features[i].unsqueeze(0)).cpu().data.numpy()\n",
    "        corr = 0\n",
    "        for j in range(tot):\n",
    "            if sample_id[j] == target[j]:\n",
    "                corr += 1\n",
    "        t_acc = corr/tot\n",
    "        \n",
    "        #print(\"Target: \", target.cpu().numpy()[:tot])\n",
    "        #print(\"Fixed sample:\" , sample_id[:tot])\n",
    "        #print(\"Acc: \", t_acc)\n",
    "        metrics['acc'][objs[i]].append(t_acc)\n",
    "        \n",
    "        \n",
    "        g = decoder.my_sample(features[i].unsqueeze(0))\n",
    "        g_distance = score_seqs(g,target[:tot])\n",
    "        metrics['greedy'][objs[i]].append(g_distance)\n",
    "        #print(\"Greedy sample:\",g.data.cpu().numpy())\n",
    "        #print(\"Greedy: \",g_distance)\n",
    "        \n",
    "        beam.start_beams(features[i])\n",
    "        beam.sample_beams()\n",
    "        b,_ = beam.get_best()\n",
    "        b_distance = score_seqs(b,target[:tot])\n",
    "        metrics['beam'][objs[i]].append(b_distance)\n",
    "        #print(\"Beam sample:\",b.data.cpu().numpy().T[0])\n",
    "        #print(\"Beam: \",b_distance)\n",
    "        #print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc     0.36\n",
      "greedy  0.50\n",
      "beam    0.49\n"
     ]
    }
   ],
   "source": [
    "for key in metrics:\n",
    "    results = metrics[key]\n",
    "    all_res = []\n",
    "    for item,val in results.items():\n",
    "        all_res += val\n",
    "    print(\"{:7} {:.2f}\".format(key,np.array(all_res).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_to_ix['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat   & 0.20 \\\\\n",
      "big    & 0.28 \\\\\n",
      "long   & 0.35 \\\\\n",
      "small  & 0.36 \\\\\n",
      "tall   & 0.44 \\\\\n",
      "-------------\n",
      "flat   & 0.15 & cd           \\\\\n",
      "flat   & 0.16 & key          \\\\\n",
      "flat   & 0.17 & button       \\\\\n",
      "flat   & 0.21 & game_card    \\\\\n",
      "long   & 0.24 & cigarette    \\\\\n",
      "flat   & 0.25 & credit_card  \\\\\n",
      "big    & 0.25 & coffee_mug   \\\\\n",
      "big    & 0.26 & plate        \\\\\n",
      "flat   & 0.27 & comb         \\\\\n",
      "big    & 0.29 & book         \\\\\n",
      "long   & 0.33 & marker       \\\\\n",
      "big    & 0.33 & bowl         \\\\\n",
      "small  & 0.33 & match        \\\\\n",
      "small  & 0.34 & shell        \\\\\n",
      "small  & 0.35 & screw        \\\\\n",
      "long   & 0.36 & screw_driver \\\\\n",
      "small  & 0.37 & french_chalk \\\\\n",
      "tall   & 0.37 & toy          \\\\\n",
      "small  & 0.40 & rubber_band  \\\\\n",
      "tall   & 0.43 & chestnut     \\\\\n",
      "tall   & 0.44 & matchbox     \\\\\n",
      "tall   & 0.45 & tape         \\\\\n",
      "tall   & 0.46 & glasses      \\\\\n",
      "long   & 0.48 & shashlik     \\\\\n",
      "tall   & 0.48 & salt_shaker  \\\\\n",
      "-------------\n",
      "acc    & 0.33\n",
      "#############\n",
      "\n",
      "big    & 0.34 \\\\\n",
      "flat   & 0.45 \\\\\n",
      "tall   & 0.48 \\\\\n",
      "long   & 0.51 \\\\\n",
      "small  & 0.56 \\\\\n",
      "-------------\n",
      "big    & 0.31 & coffee_mug   \\\\\n",
      "big    & 0.33 & bowl         \\\\\n",
      "long   & 0.34 & cigarette    \\\\\n",
      "big    & 0.36 & book         \\\\\n",
      "flat   & 0.37 & button       \\\\\n",
      "big    & 0.37 & plate        \\\\\n",
      "flat   & 0.40 & key          \\\\\n",
      "tall   & 0.42 & toy          \\\\\n",
      "flat   & 0.45 & comb         \\\\\n",
      "small  & 0.45 & shell        \\\\\n",
      "tall   & 0.48 & matchbox     \\\\\n",
      "tall   & 0.48 & glasses      \\\\\n",
      "flat   & 0.48 & cd           \\\\\n",
      "tall   & 0.48 & chestnut     \\\\\n",
      "flat   & 0.49 & credit_card  \\\\\n",
      "tall   & 0.49 & tape         \\\\\n",
      "flat   & 0.49 & game_card    \\\\\n",
      "tall   & 0.50 & salt_shaker  \\\\\n",
      "long   & 0.52 & marker       \\\\\n",
      "long   & 0.55 & screw_driver \\\\\n",
      "small  & 0.57 & screw        \\\\\n",
      "small  & 0.58 & french_chalk \\\\\n",
      "small  & 0.60 & match        \\\\\n",
      "long   & 0.60 & shashlik     \\\\\n",
      "small  & 0.61 & rubber_band  \\\\\n",
      "-------------\n",
      "greedy & 0.47\n",
      "#############\n",
      "\n",
      "flat   & 0.43 \\\\\n",
      "tall   & 0.44 \\\\\n",
      "big    & 0.45 \\\\\n",
      "long   & 0.54 \\\\\n",
      "small  & 0.59 \\\\\n",
      "-------------\n",
      "flat   & 0.34 & button       \\\\\n",
      "flat   & 0.36 & key          \\\\\n",
      "flat   & 0.39 & comb         \\\\\n",
      "tall   & 0.40 & tape         \\\\\n",
      "long   & 0.41 & cigarette    \\\\\n",
      "big    & 0.42 & coffee_mug   \\\\\n",
      "tall   & 0.43 & glasses      \\\\\n",
      "tall   & 0.44 & toy          \\\\\n",
      "tall   & 0.45 & chestnut     \\\\\n",
      "big    & 0.46 & bowl         \\\\\n",
      "tall   & 0.46 & salt_shaker  \\\\\n",
      "big    & 0.46 & plate        \\\\\n",
      "tall   & 0.46 & matchbox     \\\\\n",
      "big    & 0.47 & book         \\\\\n",
      "flat   & 0.48 & credit_card  \\\\\n",
      "flat   & 0.50 & game_card    \\\\\n",
      "flat   & 0.50 & cd           \\\\\n",
      "small  & 0.54 & shell        \\\\\n",
      "small  & 0.57 & screw        \\\\\n",
      "long   & 0.58 & marker       \\\\\n",
      "long   & 0.58 & screw_driver \\\\\n",
      "long   & 0.59 & shashlik     \\\\\n",
      "small  & 0.60 & match        \\\\\n",
      "small  & 0.62 & french_chalk \\\\\n",
      "small  & 0.62 & rubber_band  \\\\\n",
      "-------------\n",
      "beam   & 0.48\n",
      "#############\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in metrics:\n",
    "    results = metrics[key]\n",
    "    all_res = []\n",
    "    cats = []\n",
    "    for cat, objs in obj_categories.items():\n",
    "        cat_acc = []\n",
    "        for obj in objs:\n",
    "            cat_acc += results[obj_to_ix[obj]]\n",
    "        cats.append((np.array(cat_acc).mean(),cat))\n",
    "        cats = sorted(cats)\n",
    "    for acc,cat in cats:\n",
    "        print(\"{:6} & {:.2f} \\\\\\\\\".format(cat,acc))\n",
    "        \n",
    "    print(\"-------------\")\n",
    "    items = []\n",
    "    for item,val in results.items():\n",
    "        items.append((np.array(val).mean(),ix_to_obj[item]))\n",
    "        all_res += val\n",
    "        \n",
    "    items = sorted(items)\n",
    "    for acc, item in items:\n",
    "        print(\"{:6} & {:.2f} & {:12} \\\\\\\\\".format(obj_to_cat[item],acc,item))\n",
    "        \n",
    "    print(\"-------------\")\n",
    "    \n",
    "    print(\"{:6} & {:.2f}\".format(key,np.array(all_res).mean()))\n",
    "    \n",
    "    print(\"#############\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain_levenshtein(a,b):\n",
    "    \"Calculates the Levenshtein distance between a and b.\"\n",
    "    n, m = len(a), len(b)\n",
    "    if n > m:\n",
    "        # Make sure n <= m, to use O(min(n,m)) space\n",
    "        a,b = b,a\n",
    "        n,m = m,n\n",
    "        \n",
    "    current = range(n+1)\n",
    "    for i in range(1,m+1):\n",
    "        previous, current = current, [i]+[0]*n\n",
    "        for j in range(1,n+1):\n",
    "            add, delete = previous[j]+1, current[j-1]+1\n",
    "            change = previous[j-1]\n",
    "            if a[j-1] != b[i-1]:\n",
    "                change = change + 1\n",
    "            current[j] = min(add, delete, change)\n",
    "            \n",
    "    return current[n]\n",
    "\n",
    "def score_markov(pred,targ):\n",
    "    distance = plain_levenshtein(pred,targ)\n",
    "    return 1 - ((distance + 1)/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(dataloader,category):\n",
    "    seqs = []\n",
    "    objs_in_category = obj_categories[category]\n",
    "    #print(objs_in_category)\n",
    "    for i, (images, captions, lengths, objs) in enumerate(dataloader):\n",
    "        print(\"\\r{}/{}\".format(i,len(dataloader)),end=\"\")\n",
    "        for caption, length, obj in zip(captions,lengths, objs):\n",
    "            if ix_to_obj[obj] in objs_in_category:\n",
    "                seqs.append(caption[:length].cpu().numpy())\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['key', 'button', 'cd', 'credit_card', 'game_card', 'comb']\n",
      "80/81"
     ]
    }
   ],
   "source": [
    "#a = get_category(dataloaders['test'],'flat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(tag,vocab):\n",
    "    state = np.zeros(len(vocab))\n",
    "    state[tag] += 1\n",
    "    return state\n",
    "\n",
    "def sample(distr,vocab):\n",
    "    return np.random.choice(len(vocab),p=distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def test_category(category,training_loader, test_loader):\n",
    "    markov = np.zeros((len(vocab),len(vocab)))\n",
    "    starts = np.zeros((len(vocab)))\n",
    "    print(\"Computing Markov for {}\".format(category))\n",
    "    training_samples = get_category(training_loader,category)\n",
    "    for seq in training_samples:\n",
    "        #seq = generate_label(category)\n",
    "        #seq.append(vocab.stop)\n",
    "        starts[seq[0]] += 1\n",
    "        for i,j in zip(seq,seq[1:]):\n",
    "            markov[i][j] += 1\n",
    "    print()\n",
    "    print(\"Normalizing Markov for {}\".format(category))\n",
    "    starts /= starts.sum()\n",
    "    markov = normalize(markov,axis=1,norm='l1')\n",
    "\n",
    "    test_trials = get_category(test_loader,category)\n",
    "    acc = []\n",
    "    print()\n",
    "    print(\"Testing Markov for {}\".format(category))\n",
    "    lev = []\n",
    "    for target_seq in test_trials:\n",
    "        generated_sequence = []\n",
    "        curr_tag = sample(starts,vocab)\n",
    "        curr_state = vectorize(curr_tag,vocab)\n",
    "        correct = 0\n",
    "        tot = len(target_seq)\n",
    "        generated_sequence.append(curr_tag)\n",
    "        for tag in target_seq:\n",
    "            if(curr_tag == tag):\n",
    "                correct += 1\n",
    "            curr_state = curr_state.dot(markov)\n",
    "            curr_state /= curr_state.sum()\n",
    "            curr_tag = sample(curr_state,vocab)\n",
    "            generated_sequence.append(curr_tag)\n",
    "        acc.append(correct/tot)\n",
    "        \n",
    "        lev.append(score_markov(generated_sequence,target_seq))\n",
    "    \n",
    "    tag_acc = np.array(acc).mean()\n",
    "    lev_acc = np.array(lev).mean()\n",
    "    print(\"Test {}: Acc {:.2f} - Lev {:.2f}\".format(category, tag_acc, lev_acc))\n",
    "    print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Markov for flat\n",
      "376/377\n",
      "Normalizing Markov for flat\n",
      "80/81\n",
      "Testing Markov for flat\n",
      "Test flat: Acc 0.21 - Lev 0.17\n",
      "-------------------------------\n",
      "Computing Markov for tall\n",
      "376/377\n",
      "Normalizing Markov for tall\n",
      "80/81\n",
      "Testing Markov for tall\n",
      "Test tall: Acc 0.25 - Lev 0.18\n",
      "-------------------------------\n",
      "Computing Markov for big\n",
      "376/377\n",
      "Normalizing Markov for big\n",
      "80/81\n",
      "Testing Markov for big\n",
      "Test big: Acc 0.18 - Lev 0.16\n",
      "-------------------------------\n",
      "Computing Markov for long\n",
      "376/377\n",
      "Normalizing Markov for long\n",
      "80/81\n",
      "Testing Markov for long\n",
      "Test long: Acc 0.30 - Lev 0.26\n",
      "-------------------------------\n",
      "Computing Markov for small\n",
      "376/377\n",
      "Normalizing Markov for small\n",
      "80/81\n",
      "Testing Markov for small\n",
      "Test small: Acc 0.28 - Lev 0.29\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "for cat in obj_categories:\n",
    "    test_category(cat,dataloaders['train'], dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21200000000000002"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.17 + 0.18 + 0.16 + 0.26 + 0.29)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.504"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.46 + 0.48 + 0.43 + 0.57 + 0.58)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.484"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.45 + 0.48 + 0.39 + 0.56 + 0.54)/5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
