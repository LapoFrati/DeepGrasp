{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn, autograd, stack, cat\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "vgg_urls = {\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class partialVGG(nn.Module):\n",
    "\n",
    "    def __init__(self, target_layer):\n",
    "        super(partialVGG, self).__init__()\n",
    "        self.target_layer = target_layer\n",
    "        self.features = self.make_layers()\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.features:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def make_layers(self, batch_norm=False):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "            if(len(layers) >= self.target_layer+1):\n",
    "                return nn.ModuleList(layers)\n",
    "        return nn.ModuleList(layers)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "def get_partialVGG(target_layer):\n",
    "    model = partialVGG(target_layer)\n",
    "    \n",
    "    pretrained_dict = model_zoo.load_url(vgg_urls['vgg16'])\n",
    "\n",
    "    model_dict = model.state_dict()\n",
    "\n",
    "    # 1. filter out unnecessary keys\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    # 2. overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict) \n",
    "    # 3. load the new state dict\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model , VGG_features_sizes(target_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_features_sizes(target_layer):\n",
    "    im_size = 224\n",
    "    filters = 64\n",
    "    num_features = []\n",
    "    layers = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "    for layer in layers:\n",
    "        if layer == 'M':\n",
    "            im_size //= 2\n",
    "            num_features.append(im_size * im_size * filters)\n",
    "            #print(\"{}\\t{} : {} features\".format(len(num_features)-1,'MAXP',num_features[len(num_features)-1]))\n",
    "        else:\n",
    "            filters = layer\n",
    "            num_features.append(im_size * im_size * filters) # conv\n",
    "            #print(\"{}\\t{} : {} features\".format(len(num_features)-1,'CONV',num_features[len(num_features)-1]))\n",
    "            num_features.append(im_size * im_size * filters) # relu\n",
    "            #print(\"{}\\t{} : {} features\".format(len(num_features)-1,'RELU',num_features[len(num_features)-1]))\n",
    "    return num_features[target_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG_features_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tCONV : 3211264 features\n",
      "1\tRELU : 3211264 features\n",
      "2\tCONV : 3211264 features\n",
      "3\tRELU : 3211264 features\n",
      "4\tMAXP : 802816 features\n",
      "5\tCONV : 1605632 features\n",
      "6\tRELU : 1605632 features\n",
      "7\tCONV : 1605632 features\n",
      "8\tRELU : 1605632 features\n",
      "9\tMAXP : 401408 features\n",
      "10\tCONV : 802816 features\n",
      "11\tRELU : 802816 features\n",
      "12\tCONV : 802816 features\n",
      "13\tRELU : 802816 features\n",
      "14\tCONV : 802816 features\n",
      "15\tRELU : 802816 features\n",
      "16\tMAXP : 200704 features\n",
      "17\tCONV : 401408 features\n",
      "18\tRELU : 401408 features\n",
      "19\tCONV : 401408 features\n",
      "20\tRELU : 401408 features\n",
      "21\tCONV : 401408 features\n",
      "22\tRELU : 401408 features\n",
      "23\tMAXP : 100352 features\n",
      "24\tCONV : 100352 features\n",
      "25\tRELU : 100352 features\n",
      "26\tCONV : 100352 features\n",
      "27\tRELU : 100352 features\n",
      "28\tCONV : 100352 features\n",
      "29\tRELU : 100352 features\n",
      "30\tMAXP : 25088 features\n"
     ]
    }
   ],
   "source": [
    "#vgg, features = get_partialVGG(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pysource]",
   "language": "python",
   "name": "conda-env-pysource-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
